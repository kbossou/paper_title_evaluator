{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c9c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 02:18:16.541890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 02:18:17.269641: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-12 02:18:17.269675: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-12 02:18:19.136911: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-12 02:18:19.137311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-12 02:18:19.137353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435897d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "tfhub_handle_preprocess = \"tfhub_models/bert_en_uncased_preprocess\"\n",
    "# tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "tfhub_handle_encoder = \"tfhub_models/bert_en_uncased_L-12_H-768_A-12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7be4fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 02:18:21.251586: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-12 02:18:21.252313: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-12 02:18:21.252394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (djimadja): /proc/driver/nvidia/version does not exist\n",
      "2022-12-12 02:18:21.253061: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocessor = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28b051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_mask', 'input_type_ids', 'input_word_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocessor(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6f4cc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 02:18:31.968367: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "bert_encoder = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcda3be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: tfhub_models/bert_en_uncased_L-12_H-768_A-12\n",
      "Pooled Outputs Shape:(1, 768)\n",
      "Pooled Outputs Values:[-0.92169875 -0.39353448 -0.5393166   0.6825623   0.43848425 -0.14021152\n",
      "  0.87747115  0.26043344 -0.63112926 -0.9999658  -0.2631999   0.8510528 ]\n",
      "Sequence Outputs Shape:(1, 128, 768)\n",
      "Sequence Outputs Values:[[ 0.19451588  0.25141683  0.19075048 ... -0.24845086  0.3856856\n",
      "   0.1329101 ]\n",
      " [-0.5947865  -0.39420336  0.2524569  ... -0.7694673   1.1564162\n",
      "   0.32475716]\n",
      " [ 0.0064151  -0.15766409  0.5461024  ... -0.17451069  0.60289675\n",
      "   0.42672223]\n",
      " ...\n",
      " [ 0.2194835  -0.20927066  0.5386831  ...  0.24693537  0.18250984\n",
      "  -0.44427064]\n",
      " [ 0.01080252 -0.44553122  0.35990965 ...  0.31722802  0.23562811\n",
      "  -0.63070595]\n",
      " [ 0.29321158 -0.10581908  0.6114752  ...  0.20745802  0.1449466\n",
      "  -0.3535337 ]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_encoder(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0244a736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
       "array([[-0.8435169 , -0.51327264, -0.88845724, ..., -0.74748874,\n",
       "        -0.75314736,  0.91964483],\n",
       "       [-0.8720836 , -0.5054398 , -0.9444668 , ..., -0.85847515,\n",
       "        -0.7174535 ,  0.88082975]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocessor(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']\n",
    "\n",
    "get_sentence_embeding([\n",
    "    \"500$ discount. hurry up\", \n",
    "    \"Bhavin, are you up for a volleybal game tomorrow?\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d197dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "774eaa9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18145, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = pd.read_csv('datasets/ai_papers_00-17.csv')\n",
    "papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09e2e75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>num_of_citations</th>\n",
       "      <th>conference</th>\n",
       "      <th>year</th>\n",
       "      <th>is_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Value ordering for finding all solutions</td>\n",
       "      <td>44</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Conceptual Graph Approach for the Generation...</td>\n",
       "      <td>31</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exploiting image contents in web search</td>\n",
       "      <td>34</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best-First Utility-Guided Search</td>\n",
       "      <td>31</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ambiguous part-of-speech tagging for improving...</td>\n",
       "      <td>30</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_title  num_of_citations  \\\n",
       "0           Value ordering for finding all solutions                44   \n",
       "1  A Conceptual Graph Approach for the Generation...                31   \n",
       "2            Exploiting image contents in web search                34   \n",
       "3                   Best-First Utility-Guided Search                31   \n",
       "4  Ambiguous part-of-speech tagging for improving...                30   \n",
       "\n",
       "  conference  year  is_link  \n",
       "0      IJCAI  2005     True  \n",
       "1      IJCAI  2007     True  \n",
       "2      IJCAI  2007     True  \n",
       "3      IJCAI  2007     True  \n",
       "4      IJCAI  2007     True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f78dbcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median is 10.0\n",
      "Cut off used is 10\n"
     ]
    }
   ],
   "source": [
    "CUT_OFF = papers['num_of_citations'].median()\n",
    "print(f\"Median is {CUT_OFF}\")\n",
    "CUT_OFF = int(CUT_OFF)\n",
    "# CUT_OFF = 15\n",
    "print(f\"Cut off used is {CUT_OFF}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e9139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers['target'] = papers['num_of_citations'].apply(lambda x: True if x >= CUT_OFF else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db693f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>num_of_citations</th>\n",
       "      <th>conference</th>\n",
       "      <th>year</th>\n",
       "      <th>is_link</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Value ordering for finding all solutions</td>\n",
       "      <td>44</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>2005</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Conceptual Graph Approach for the Generation...</td>\n",
       "      <td>31</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exploiting image contents in web search</td>\n",
       "      <td>34</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best-First Utility-Guided Search</td>\n",
       "      <td>31</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ambiguous part-of-speech tagging for improving...</td>\n",
       "      <td>30</td>\n",
       "      <td>IJCAI</td>\n",
       "      <td>2007</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_title  num_of_citations  \\\n",
       "0           Value ordering for finding all solutions                44   \n",
       "1  A Conceptual Graph Approach for the Generation...                31   \n",
       "2            Exploiting image contents in web search                34   \n",
       "3                   Best-First Utility-Guided Search                31   \n",
       "4  Ambiguous part-of-speech tagging for improving...                30   \n",
       "\n",
       "  conference  year  is_link  target  \n",
       "0      IJCAI  2005     True    True  \n",
       "1      IJCAI  2007     True    True  \n",
       "2      IJCAI  2007     True    True  \n",
       "3      IJCAI  2007     True    True  \n",
       "4      IJCAI  2007     True    True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eb93e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(papers['paper_title'], papers['target'], stratify=papers['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed386c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32df584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad2e978e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bossou/Desktop/Research/titlevator/venv/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocessor(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58b05ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'sequence_output':  109482241   ['keras_layer[0][0]',            \n",
      "                                 (None, 128, 768),                'keras_layer[0][1]',            \n",
      "                                 'pooled_output': (               'keras_layer[0][2]']            \n",
      "                                None, 768),                                                       \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)]}                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f314afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.Recall(name='AUC')\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ecacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "426/426 [==============================] - 3186s 7s/step - loss: 0.7068 - accuracy: 0.5168 - precision: 0.5323 - recall: 0.6023 - AUC: 0.6023\n",
      "Epoch 2/10\n",
      "426/426 [==============================] - 3089s 7s/step - loss: 0.7030 - accuracy: 0.5254 - precision: 0.5399 - recall: 0.6069 - AUC: 0.6069\n",
      "Epoch 3/10\n",
      "426/426 [==============================] - 3059s 7s/step - loss: 0.6957 - accuracy: 0.5332 - precision: 0.5463 - recall: 0.6173 - AUC: 0.6173\n",
      "Epoch 4/10\n",
      "426/426 [==============================] - 3056s 7s/step - loss: 0.6941 - accuracy: 0.5384 - precision: 0.5516 - recall: 0.6127 - AUC: 0.6127\n",
      "Epoch 5/10\n",
      "426/426 [==============================] - 3053s 7s/step - loss: 0.6932 - accuracy: 0.5460 - precision: 0.5580 - recall: 0.6221 - AUC: 0.6221\n",
      "Epoch 6/10\n",
      "426/426 [==============================] - 16021s 38s/step - loss: 0.6896 - accuracy: 0.5492 - precision: 0.5609 - recall: 0.6240 - AUC: 0.6240\n",
      "Epoch 7/10\n",
      "426/426 [==============================] - 2960s 7s/step - loss: 0.6875 - accuracy: 0.5500 - precision: 0.5626 - recall: 0.6149 - AUC: 0.6149\n",
      "Epoch 8/10\n",
      "426/426 [==============================] - 3431s 8s/step - loss: 0.6895 - accuracy: 0.5457 - precision: 0.5574 - recall: 0.6249 - AUC: 0.6249\n",
      "Epoch 9/10\n",
      "426/426 [==============================] - 3809s 9s/step - loss: 0.6873 - accuracy: 0.5567 - precision: 0.5678 - recall: 0.6272 - AUC: 0.6272\n",
      "Epoch 10/10\n",
      " 68/426 [===>..........................] - ETA: 44:00 - loss: 0.6842 - accuracy: 0.5630 - precision: 0.5718 - recall: 0.6399 - AUC: 0.6399"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b045c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
